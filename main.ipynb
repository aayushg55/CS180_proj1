{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def translate_no_pad(im, translation):\n",
    "    \"\"\"\n",
    "    translate an image `tx` to the right, `ty` down\n",
    "    :param image (h, w, c) array\n",
    "    :param tx (float) pixels to translate right\n",
    "    :param ty (float) pixels to translate down\n",
    "    \"\"\"\n",
    "    ty, tx = translation\n",
    "    h, w = im.shape[:2]\n",
    "    mat = translation_matrix = np.array([\n",
    "        [1, 0, tx],\n",
    "        [0, 1, ty]\n",
    "    ], dtype=np.float32)\n",
    "    return cv2.warpAffine(im, mat, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'data/'\n",
    "out_dir = 'out_path/'\n",
    "\n",
    "def read_img(img_name, img_dir = 'data/'):\n",
    "    img = plt.imread(img_dir + img_name)\n",
    "    img = img / 255\n",
    "    if '.tif' in img_name:\n",
    "        img /= 255\n",
    "    return img\n",
    "\n",
    "# translates the image with a circular shift, where translation = (dh, dw)\n",
    "def translate_circ(img, translation):\n",
    "    return np.roll(np.roll(img, translation[0], axis=0), translation[1], axis=1)\n",
    "\n",
    "def split_into_channels(img):\n",
    "    # compute the height of each part (just 1/3 of total)\n",
    "    height = np.floor(img.shape[0] / 3.0).astype(np.int_)\n",
    "\n",
    "    # separate color channels\n",
    "    b, g, r = img[:height], img[height: 2*height], img[2*height: 3*height]\n",
    "    return r, g, b\n",
    "\n",
    "# computes ssd score between two images\n",
    "def ssd(img1, img2):\n",
    "    ssd_score = np.sum((img1 - img2)**2)\n",
    "    return ssd_score\n",
    "\n",
    "# computes the normalized cross correlation, by first demeaning and normalizing\n",
    "def ncc(img_1, img_2):\n",
    "    n1 = img_1-np.mean(img_1)\n",
    "    n2 = img_2-np.mean(img_2)\n",
    "    n1 = n1 / np.sqrt(np.sum(n1**2))\n",
    "    n2 = n2 / np.sqrt(np.sum(n2**2))\n",
    "    return -np.sum(img_1*img_2)\n",
    "    \n",
    "# Brute force algorithm which searches in the [min_tr, max_tr] space for the best translation,\n",
    "# calculates the similarity score based on a given metric\n",
    "def naive_align_two_channels(c1, c2, metric=ssd, min_tr_h=-15, max_tr_h=15, min_tr_w=-15, max_tr_w=15, translate=translate_circ):\n",
    "    min_score = float('inf')\n",
    "    translation = 0, 0\n",
    "    for u in range(min_tr_h, max_tr_h+1):\n",
    "        for v in range(min_tr_w, max_tr_w+1):\n",
    "            test_trans = (u,v)\n",
    "            c1_trans = translate(c1, test_trans)\n",
    "            s = metric(c1_trans, c2)\n",
    "            if s < min_score:\n",
    "                translation = test_trans\n",
    "                min_score = s\n",
    "    return translation, min_score\n",
    "\n",
    "# Stacks the channels to get an RGB image\n",
    "def stack_channels(r, g, b):\n",
    "    img_out = np.dstack([r, g, b])\n",
    "    return img_out\n",
    "\n",
    "# Aligns images by a hard-coded translation\n",
    "def process_hard_coded(r, g, b, trans_r, trans_g):\n",
    "    r = translate(r, trans_r)\n",
    "    g = translate(g, trans_g)\n",
    "    img_aligned = stack_channels(r, g, b)\n",
    "    return img_aligned\n",
    "\n",
    "# Naively crops the image by a fixed percentage from all sides\n",
    "def crop_border(img, ratio = 0.2):\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int(h*(ratio/2)):int(h*(1-ratio/2)), int(w*(ratio/2)):int(w*(1-ratio/2))]\n",
    "\n",
    "# Given an unsplit image, returns the aligned image and translations needed using the single-scale search.\n",
    "def process_single_scale(img, metric = None, precrop = False, translate = translate_circ):\n",
    "    r, g, b = split_into_channels(img)\n",
    "    trans_r, trans_g = (0,0), (0,0)\n",
    "    if metric:\n",
    "        r_cr, g_cr, b_cr = r, g, b\n",
    "        if precrop:\n",
    "            r_cr, g_cr, b_cr = map(crop_border, (r, g, b))\n",
    "        trans_r, _ = naive_align_two_channels(r_cr, b_cr, metric=metric, translate=translate)\n",
    "        trans_g, _ = naive_align_two_channels(g_cr, b_cr, metric=metric, translate=translate)\n",
    "\n",
    "        r = translate(r, trans_r)\n",
    "        g = translate(g, trans_g)\n",
    "    img_aligned = stack_channels(r, g, b)\n",
    "    return img_aligned, trans_r, trans_g\n",
    "\n",
    "def save_img(fname, img_out, out_dir = 'out_path/'):\n",
    "    img_out = (img_out*255).astype(np.uint8)\n",
    "    plt.imsave(out_dir + fname, img_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiscale Pyramid Algorithm\n",
    "import skimage\n",
    "import math\n",
    "\n",
    "#Computes the alignment needed to align the channels, searching in the space\n",
    "# [-refine, refine] of displacements from the previous level's optimal displacements after upscaling\n",
    "def compute_pyramid_alignment(img1, img2, metric, refine=2, translate=translate_circ):\n",
    "    min_size, max_size = 100, 4000\n",
    "    resize_ratio = 2\n",
    "    h, w = img1.shape[:2]\n",
    "\n",
    "    num_times_downscale = max(math.floor(math.log2(h/min_size)), math.floor(math.log2(w/min_size)))\n",
    "    scale_factor = pow(1/resize_ratio, num_times_downscale)\n",
    "    \n",
    "    num_pyramid_search = 0\n",
    "    start_search_space = (-20, 20)\n",
    "    min_score = float('inf')\n",
    "    best_trans = (0,0)\n",
    "    \n",
    "    min_tr_h, max_tr_h = (0,0)\n",
    "    min_tr_w, max_tr_w = (0,0)\n",
    "\n",
    "    while scale_factor * h < max_size and scale_factor * w < max_size and num_times_downscale - num_pyramid_search >= 0:\n",
    "        num_pyramid_search += 1\n",
    "        img1_rs = skimage.transform.rescale(img1, scale_factor)\n",
    "        img2_rs = skimage.transform.rescale(img2, scale_factor)\n",
    "\n",
    "        min_tr_h, max_tr_h = start_search_space if num_pyramid_search == 1 else (best_trans[0]-refine, best_trans[0]+refine)\n",
    "        min_tr_w, max_tr_w = start_search_space if num_pyramid_search == 1 else (best_trans[1]-refine, best_trans[1]+refine)\n",
    "                \n",
    "        best_trans, min_score = naive_align_two_channels(img1_rs, img2_rs, metric, min_tr_h, max_tr_h, min_tr_w, max_tr_w, translate)\n",
    "\n",
    "        scale_factor *= resize_ratio\n",
    "        # Doubles the previous levels translations since it is downscaled by a factor of 2\n",
    "        if num_times_downscale - num_pyramid_search >= 0:\n",
    "            best_trans = best_trans[0] * 2, best_trans[1] * 2\n",
    "    \n",
    "    while num_times_downscale - num_pyramid_search > 0:\n",
    "        num_pyramid_search += 1\n",
    "        best_trans = best_trans[0] * 2, best_trans[1] * 2\n",
    "        \n",
    "    return best_trans\n",
    "\n",
    "contrast_funcs = {\n",
    "    'equalize': lambda x: skimage.exposure.equalize_hist(x),\n",
    "    'rescale': lambda x: skimage.exposure.rescale_intensity(x, in_range='image', out_range=(0,1)),\n",
    "    'adapt_eq': lambda x: skimage.exposure.equalize_adapthist(x, clip_limit=0.008)\n",
    "}\n",
    "\n",
    "# Computes the translations needed to align an unsplit image and returns the processed image\n",
    "def process_pyramid_scale(img, conv_filter = True, refine = 2, metric = ssd, precrop = True, postcrop = True, auto_contrast='adapt_eq', translate = translate_circ):\n",
    "    r, g, b = split_into_channels(img)\n",
    "    trans_r, trans_g = (0,0), (0,0)\n",
    "    \n",
    "    if metric:\n",
    "        r_pr, g_pr, b_pr = r, g, b\n",
    "        # Crops a fixed portion of the image to remove border artifacts to aid in alignment.\n",
    "        if precrop:\n",
    "            r_pr, g_pr, b_pr = map(crop_border, (r, g, b))\n",
    "        # The Sobel filter is used to create a feature map of edges. The alignment \n",
    "        # is computed on these edge feature maps.\n",
    "        if conv_filter:\n",
    "           r_pr, g_pr, b_pr = map(skimage.filters.sobel, (r_pr, g_pr, b_pr))\n",
    "        \n",
    "        trans_r = compute_pyramid_alignment(r_pr, b_pr, ssd, refine, translate)\n",
    "        trans_g = compute_pyramid_alignment(g_pr, b_pr, ssd, refine, translate)\n",
    "        r = translate(r, trans_r)\n",
    "        g = translate(g, trans_g)\n",
    "    \n",
    "    img_aligned = stack_channels(r, g, b)\n",
    "    img_aligned = np.clip(img_aligned, 0, 1)\n",
    "    \n",
    "    # Crop a fixed portion of the aligned image to remove border artifacts\n",
    "    if postcrop:\n",
    "        img_aligned = crop_border(img_aligned, 0.1)\n",
    "        \n",
    "    # Applies the auto-contrast method, if specified\n",
    "    if auto_contrast:\n",
    "        img_aligned = contrast_funcs[auto_contrast](img_aligned)\n",
    "    return img_aligned, trans_r, trans_g\n",
    "\n",
    "# Performs all steps to align a given image with name img_name, including pre and post-processing\n",
    "def align_image_pyramid_scale(img_name, save=False, img_dir='data/', out_dir='out/', conv_filter=True, refine=2, metric=ssd, precrop=True, postcrop=True, auto_contrast='adapt_eq', translate=translate_circ):\n",
    "    name, extension = img_name.split('.')\n",
    "    img = read_img(img_name, img_dir=img_dir)\n",
    "    img_aligned, trans_r, trans_g = process_pyramid_scale(img, conv_filter, refine, metric, precrop, postcrop, auto_contrast, translate)\n",
    "    if save:\n",
    "        save_img(name + '.jpg', img_aligned, out_dir=out_dir)\n",
    "    return img_aligned, trans_r, trans_g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize channels of emir.tiff with and without edge detection\n",
    "import imageio\n",
    "img_name = 'emir.tif'\n",
    "out_dir = 'out/alignment_tests/'\n",
    "img = read_img(img_name)\n",
    "r,g,b = split_into_channels(img)\n",
    "r,g,b = map(crop_border, (r,g,b))\n",
    "r_edge,g_edge,b_edge = map(skimage.filters.sobel, (r,g,b))\n",
    "r, b, r_edge, b_edge = map(lambda x: (x*255).astype(np.uint8), (r, b, r_edge, b_edge))\n",
    "imageio.imwrite(out_dir+'emir_r.jpg', r)\n",
    "imageio.imwrite(out_dir+'emir_b.jpg', b)\n",
    "imageio.imwrite(out_dir+'emir_r_edge.jpg', r_edge)\n",
    "imageio.imwrite(out_dir+'emir_b_edge.jpg', b_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to visualize different contrast manipulations. \n",
    "# The histogram plotting code is taken from https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html.\n",
    "def plot_img_and_hist(image, axes, bins=256):\n",
    "    \"\"\"Plot an image along with its histogram and cumulative histogram.\n",
    "\n",
    "    \"\"\"\n",
    "    ax_img, ax_hist = axes\n",
    "    ax_cdf = ax_hist.twinx()\n",
    "\n",
    "    # Display image\n",
    "    ax_img.imshow(image, cmap=plt.cm.gray)\n",
    "    ax_img.set_axis_off()\n",
    "\n",
    "    # Display histogram\n",
    "    ax_hist.hist(image.ravel(), bins=bins, histtype='step', color='black')\n",
    "    ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n",
    "    ax_hist.set_xlabel('Pixel intensity')\n",
    "    ax_hist.set_xlim(0, 1)\n",
    "    ax_hist.set_yticks([])\n",
    "\n",
    "    # Display cumulative distribution\n",
    "    img_cdf, bins = skimage.exposure.cumulative_distribution(image, bins)\n",
    "    ax_cdf.plot(bins, img_cdf, 'r')\n",
    "    ax_cdf.set_yticks([])\n",
    "\n",
    "    return ax_img, ax_hist, ax_cdf\n",
    "\n",
    "# Plots the effect of histogram equalization, rescaling, and adaptive histogram equalization, along with the histograms and cdf.\n",
    "def plot_contrast_changes_with_histograms(img):\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    axes = np.zeros((2, 4), dtype=object)\n",
    "    axes[0, 0] = fig.add_subplot(2, 4, 1)\n",
    "    for i in range(1, 4):\n",
    "        axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\n",
    "    for i in range(0, 4):\n",
    "        axes[1, i] = fig.add_subplot(2, 4, 5+i)\n",
    "    \n",
    "    img_equalized = skimage.exposure.equalize_hist(img)\n",
    "    img_rescale = skimage.exposure.rescale_intensity(img, in_range='image', out_range=(0,1))\n",
    "    img_adapteq = skimage.exposure.equalize_adapthist(img, clip_limit=0.008)\n",
    "    \n",
    "    ax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\n",
    "    ax_img.set_title('Default')\n",
    "    \n",
    "    ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\n",
    "    ax_img.set_title('Rescaling')\n",
    "    ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_equalized, axes[:, 2])\n",
    "    ax_img.set_title('Histogram equalization')\n",
    "    ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_adapteq, axes[:, 3])\n",
    "    ax_img.set_title('Adaptive equalization')\n",
    "\n",
    "# Plots the effect of various contrast manipulations without histograms\n",
    "def plot_contrast_changes_simple(img):\n",
    "    img_equalized =  skimage.exposure.equalize_hist(img)\n",
    "    img_rescale = skimage.exposure.rescale_intensity(img, in_range='image', out_range=(0,1))\n",
    "    img_adapteq = skimage.exposure.equalize_adapthist(img, clip_limit=0.008)\n",
    "    \n",
    "    rows, columns = 2, 2\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Normal')\n",
    "\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(img_equalized)\n",
    "    plt.title('img_equalized')\n",
    "\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(img_rescale)\n",
    "    plt.title('img_rescale')\n",
    "\n",
    "    fig.add_subplot(rows, columns, 4)\n",
    "    plt.imshow(img_adapteq)\n",
    "    plt.title('img_adapteq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code to view single scale search results\n",
    "out_dir = 'out/ssd/'\n",
    "for img_name in os.listdir('data'):\n",
    "    if '.tif' not in img_name:\n",
    "        img = read_img(img_name)\n",
    "        print(img_name)\n",
    "        translate = translate_circ\n",
    "        img_aligned, trans_r, trans_g = process_single_scale(img, metric=ssd, crop=True)\n",
    "        # post_cr = crop_border(img_aligned, 0.1)\n",
    "        # print(trans_r, trans_r)\n",
    "        plt.imshow(img_aligned)\n",
    "        # save_img(img_name, img_aligned, out_dir=out_dir)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code to produce final outputs for pyramid scale search algorithm (with bells & whistles)\n",
    "# To turn extensions off, set auto_contrast=None and conv_filter=False\n",
    "out_dir = 'out/pyramid/'\n",
    "out_file = 'translations.txt'\n",
    "f = open(out_dir + out_file, \"a\")\n",
    "for img_name in os.listdir('data'):\n",
    "    img_aligned, trans_r, trans_g = align_image_pyramid_scale(img_name, save=True, out_dir=out_dir)\n",
    "    mess = 'Image {0}: ({1}, {2}), ({3}, {4})\\n'.format(img_name, trans_r[0], trans_r[1], trans_g[0], trans_g[1])\n",
    "    f.write(mess)\n",
    "    # print(trans_r, trans_g)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code to produce final outputs for pyramid scale search algorithm (with bells & whistles)\n",
    "out_dir = 'out/extra_results_no_contrast/'\n",
    "out_file = 'translations.txt'\n",
    "f = open(out_dir + out_file, \"a\")\n",
    "for img_name in os.listdir('extra_data'):\n",
    "    img_aligned, trans_r, trans_g = align_image_pyramid_scale(img_name, save=True, out_dir=out_dir, img_dir='extra_data/', auto_contrast=None)\n",
    "    mess = 'Image {0}: ({1}, {2}), ({3}, {4})\\n'.format(img_name, trans_r[0], trans_r[1], trans_g[0], trans_g[1])\n",
    "    f.write(mess)\n",
    "    # print(trans_r, trans_g)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
